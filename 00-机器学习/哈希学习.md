# 哈希学习（learning to hash）
哈希学习的目的是学到数据的二进制哈希码表示，使得哈希码尽可能地保留原空间中的近邻关系，即保相似性。
具体来说，每个数据点会被一个紧凑的二进制串编码，在原空间中相似的两个点应当被映射到哈希码空间中相似的两个点。

例如：原空间中相似的两幅图像将被映射到相似(即海明距离较小)的两个哈希码，而原空间中不相似的两幅图像将被映射到不相似(即海明距离较大)的两个哈希码。

## 带来的好处（**可以和分布式扯上关系**）
1）使用哈希码表示数据后，能显著减少数据的存储和通信开销，从而有效提高学习系统的效率。
举例来说，如果原空间中每个数据样本都被一个1024字节的向量表示，一个包含一亿个样本的数据集要占用100 GB的存储空间。相反，如果把每个数据样本哈希到一个128位的哈希码，一亿个样本的存储空间只需要1.6 GB。

2）因为通过哈希学习得到的哈希码位数(维度)一般会比原空间的维度要低，哈希学习也能降低数据维度，从而减轻维度灾难问题。

3）基于哈希学习得到的二进制哈希码可以构建索引机制，实现常数或者次线性级别的快速近邻检索，为上层学习任务的快速实现提供支撑。

## 研究现状
处于初级阶段

目前大部分哈希学习研究的思路为：针对某个机器学习场景(比如排序学习场景)或者应用场景，只要以前没有人尝试过用哈希学习的思想来加速学习过程，就可以考虑把哈希学习用进去，然后在一个传统模型(这个传统模型不用哈希学习)解决不了的数据或者应用规模上进行实验验证。

另外，特别值得一提的是，很多分布式机器学习的瓶颈在于节点间的通信开销。因此，将哈希学习引入到分布式机器学习算法，并验证哈希学习在减小通信开销方面的有效性，也是非常有意义的研究方向。