# 模型的基本假设
理解模型的基本假设，看自己的数据是否符合这种假设。任何模型都是有某种假设的，如果数据不符合这种假设，就不太可能学出有意义的模型并用于预测。


## 比如LDA（主题模型）
假设是在同样一批文档中经常共现的词，语义上往往是相关的。这种特性不仅在自然语言中成立，在一些领域，比如每个人经常访问的网址集合，可能也是成立的，所以LDA也可以拿过去用。但如果数据不符合这个特性，套用LDA就是没有意义的，比如每个球队里的队员，可能并没有因为属于一个球队而具有什么相似性。

## 比如CNN（卷积神经网络）
它的基本假设是特征的不同维度之间有局部相关性，卷积操作可以抓住这只局部相关性，形成新的特征。比如自然语言里，有重复出现的bigram，或者图像里代表性的局部像素块。不满足这种局部相关性的数据，比如收到的邮件序列，这种局部相关性很弱，那用CNN就不能抓到有用的特征。


## 比如高斯copula
在量化金融里曾被广泛使用，把债券之间非高斯的相关性用copula转化成高斯然后拟合。然而这个模型隐含的假设是这种相关性符合瘦尾分布(thin tailed distribution)，即罕见事件发生的概率非常非常低。这个不合理假设导致对黑天鹅事件概率严重低估，曾被视为2008年金融危机的根源之一。