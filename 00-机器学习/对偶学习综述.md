# 对偶学习（dual learning）
深度学习和增强学习是不是真的已经非常完美，可以解决我们面临的所有人工智能问题呢？其实答案是否定的。仔细分析一下就会发现，这两项技术都存在本质的弱点。

1）首先，目前深度学习的成功离不开大量的有标签训练数据；但是获得海量有标签数据的代价是非常高的，在某些特定的邻域甚至是不可能完成的任务。比如医疗领域的疑难杂症，本身样本就非常少，有钱也无法取得大量的有标签数据。正所谓“成也萧何，败也萧何”，大数据推动了深度学习的成功，但也成为了深度学习进一步发展的瓶颈。

2）其次，增强学习虽然不需要利用传统意义上的有标签数据，但是它的学习效率并不高，需要跟环境进行大量交互，从而获得反馈用以更新模型。然而，有时和环境的频繁交互并不现实。比如，在我们学开车的时候，依赖于频繁地和环境（周围的路况，其他的车辆）进行交互是很危险的，可能还没学会开车就已经发生交通事故了。这就解释了为什么增强学习取得成功的领域很多都是模拟环境（比如说打电子游戏、下围棋等），它们规则明确，可以无限次重复。但当把增强学习应用到一些实际场景里，需要和实际用户进行交互，还可能带有无法挽回的风险，是不是还能取得同样的效果呢？目前还没有被证实。

## 对偶学习的起因
通过分析，我们发现了一个非常重要的现象，现实中，有意义、有实用价值的人工智能任务往往是成对出现的。
比如，在做机器翻译的时候，我们既关心从英语翻译到汉语，也关心从汉语翻译回英语；
总而言之，如果能充分地利用对偶结构，就有望解决刚才提到的深度学习和增强学习的瓶颈——训练数据从哪里来、和环境的交互怎么持续进行下去。

**事实上，对偶学习是一个新的学习范式，而不单是一个技巧。它和我们熟知的很多学习范式，如无监督学习、半监督学习、cotraining、多任务学习、迁移学习都有联系，又有显著不同。**


## 对偶学习的思路
1）我们假设学习过程中有两个智能体，其中一个智能体从事的是原任务，就是从x到y的学习任务；而另外一个智能体从事的是对偶任务，也就是从y到x的学习任务。

2）假如我们把x 用第一个智能体的模型F 映射成y，再利用第二个智能体的模型G 把它反映射成x’。

3）通过比较x 和x’ 我们其实就可以获得非常有用的反馈信号。利用这些反馈信息，我们可以使用包括Policy Gradient 在内的方法，来一轮一轮地更新我们的模型，直到最终得到两个满意的模型。


## 例子1
这个对比算法，使用了全部的双语标注数据。而我们自己提出的对偶学习算法并不需要双语标注数据，用单语数据就可以进行学习和迭代了。

不过万事开头难，我们还是要给这个学习过程一个初始化。在初始化过程中，我们使用了10% 的双语语料训练了一个相对比较弱的模型，然后用对偶学习的迭代过程不断提高它；也就是说，在初始化完成之后，我们就不再使用任何双语的标注语料了，而是靠两个对偶任务互相提供反馈信息进行模型训练。


## 例子2
那么，如果我们要解决的问题并不存在一个天然的对偶任务怎么办？其实这个也没关系，即使没有物理上的对偶性，也可以通过虚拟的对偶性来完成对偶学习。
举两个例子：第一个是在深度神经网络领域常用的AutoEncoder，仔细分析一下，它其实是对偶学习的一个特例。另一个例子是最近这两年特别火的——Generative Adversarial Nets（GAN）。

# 参考资料
微软刘铁岩：对偶学习推动人工智能的新浪潮